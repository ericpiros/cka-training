# Installation of Kubernetes
One of the curriculum topics included in the exam is to install a basic cluster using kubeadm. Using kubeadm to stand up a cluster is covered [here](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/) and we can follow the instructions outlined there to stand up a basic cluster.  

# Cluster Setup
We will be setting up a 3 node cluster which will have 1 master node and 2 worker nodes. I have created a [Vagrantfile](../vagrant/virtualbox_setup/Vagrantfilevagrant/virtualbox_setup/Vagrantfile) which will stand up 4 Ubuntu 20.04 VMs. Note that this requires that you have the following installed on your machine:  
* [Vagrant](https://developer.hashicorp.com/vagrant/downloads)
* [VirtualBox](https://www.virtualbox.org/wiki/Downloads)  

Each VM is labeled accordingly:
* **Jumpbox** - the jumpbox server we can use to log into the other 3 servers. This is optional since we can directly use 'vagrant ssh' to log into the other servers.
* **Master** - the master node where we will install out control plane.
* **Node1/Node2** - the K8S worker nodes.  
More details on how to use the Vagrantfile can be found in the appropriate [readme](../vagrant/virtualbox_setup/README.md) file.  

# Cluster Notes
Before we start with the configuration, take note that in the environment that I am using here, each VM will have 2 network interface cards. The first one is the standard VirtualBox NAT interface, which will have an IP address of 10.0.2.15. The second interface card is the default VirtualBox Local network, which will be in the 192.168.56.0/24 CIDR network.  If you are using the same network CIDR as the VirtualBox local network, you may need to create your own VirtualBox local network and adjust the Vagrantfile setting and kubeadm init commands accordingly.  
Because of the dual NIC situation on the VMs, we will need to add a parameter on our kubeadm init command later to make sure that the Kubernetes API listens on the correct network.  

# Initial Setup
We will need to install a container runtime which will be used to manage containers for Kubernetes. Kubernetes supports several container runtimes as outlined [here](https://kubernetes.io/docs/setup/production-environment/container-runtimes/). We will be using [containerd](https://containerd.io/) as our runtime as it is readily availble in the Ubuntu repository.  
No matter which run time you choose, we will need to set up a few kernel modules and sysctl parameters to support the various Network Plugins that can be used.  
## Kernel Modules
* overlay
* netfilter
```
# Ensure that the modules get loaded on reboot
$ cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

# Load the modules
$ sudo modprobe overlay
$ sudo modprobe br_netfilter

# Confirm that the modules are loaded
$ lsmod | grep br_netfilter
$ lsmod | grep overlay
```  
## sysctl Parameters
* net.bridge.bridge-nf-call-iptables  = 1
* net.bridge.bridge-nf-call-ip6tables = 1
* net.ipv4.ip_forward                 = 1 
```
# sysctl params required by setup, params persist across reboots
$ cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Apply sysctl params without reboot
$ sudo sysctl --system

# Check if the parameters are set
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
```
These instructions need to be done on the following VMs: 
* Master
* Node1
* Node2

# Turning Off Swap
Swap needs to be turned off for kubelet to work properly. There is a discussion about trying to get kubelet to work with Swap enabled that you can read on [here](https://github.com/kubernetes/kubernetes/issues/53533).  
```
# Turn off swap
$ sudo swapoff -a

# And then to disable swap on startup in /etc/fstab
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

# Check that Swap is off:
$ free
``` 
The second command will comment out the swap configuration line in /etc/fstab so that it stays disabled after reboots:
```
# /etc/fstab: static file system information.
#
# Use 'blkid' to print the universally unique identifier for a
# device; this may be used with UUID= as a more robust way to name devices
# that works even if disks are added and removed. See fstab(5).
#
# <file system> <mount point>   <type>  <options>       <dump>  <pass>
# / was on /dev/ubuntu-vg/ubuntu-lv during curtin installation
/dev/disk/by-id/dm-uuid-LVM-Ca1uwAMAqC3gRhiIaJvSUOenzOKwkEP8eIuR8UblTBCexq0grl4M8Fc8Jyb3cudy / ext4 defaults 0 1
# /boot was on /dev/sda2 during curtin installation
/dev/disk/by-uuid/05435722-8e7e-40aa-b5d2-5184c0b6689d /boot ext4 defaults 0 1
# The line below is what will be removed.
/swap.img       none    swap    sw      0       0
#VAGRANT-BEGIN
# The contents below are automatically generated by Vagrant. Do not modify.
vagrant /vagrant vboxsf uid=1000,gid=1000,_netdev 0 0
#VAGRANT-END
``` 

# Installing containerd
Since we are running Ubuntu, installing containerd is pretty straight forward:
```
$ sudo apt update
$ sudo apt install -y containerd
```
Take note that since we are going to install Kubernetes 1.26, we will require containerd version 1.6.0 and higher as mentioned in [this](https://kubernetes.io/blog/2022/12/09/kubernetes-v1-26-release/) announcement. If you are using an older version of Ubuntu, you may want to check what version is included in the repository. As of 4/15/2023, version 1.6.12 is availble on Ubuntu 20.04.
## Configuring containerd
We will need to create a configuration file for containerd. We can output the default config by passing the 'config default' parameter to containerd.  The config should be placed in '/etc/containerd/config.toml'.  
```
# Create the containerd directory
$ sudo mkdir -p /etc/containerd

# Generate the default config
$ sudo containerd config default | sudo tee /etc/containerd/config.toml

# Restart containerd to pick up the new settings
$ sudo systemctl restart containerd

# Check that containerd is running
$ sudo systemctl status containerd
```

# Installing Kubeadm, Kubelet and Kubectl
Now we can start working on installing the tools that we will need to spin up the cluster. First lets add the Kubernetes repository:  
```
# If it is not yet installed, let us install curl, apt-transport-httpos and ca-certificates
$ sudo apt update
$ sudo apt install -y apt-transport-https ca-certificates curl

# Create the keyrings directory
$ sudo mkdir -p /etc/apt/keyrings

# Download the Google Cloud public key
sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg

# Add the Kubernetes repository:
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

# Install kubeadm, kubelet and kubectl
$ sudo apt update
$ sudo apt install -y kubeadm=1.26.0-00 kubectl=1.26.0-00 kubelet=1.26.0-00

# Hold the above installed packages so that they do not get accidentally upgraded when I run a apt upgrade.
$ sudo apt-mark hold kubeadm kubectl kubelet

# Check that they are installed properly
$ kubectl version
$ sudo kubeadm --version
$ sudo systemctl status kubelet
```

# Bootstrapping the Control Plane
This [page](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/) contains instruction on setting up a simple Kubernetes cluster. Technically we only need to run 'kubeadm init' to get started, however there are several kubeadm init [parameters](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/) that are worth configuring for my environment:  
## kubeadm init parameters
* **--apiserver-advertise-address** - by default kubeadm will set the API server IP to what is set to the default gateway on your server. This is not ideal for my setup as the default gateway on my VMs points to the VirtualBox NAT network. So I will need to specify the IP address of the Master server (192.168.56.5 on the Vagrantfile) to ensure that it advertises the correct IP address.
 * **--kubernetes-version** - by default kubeadm will install the latest version of kubernetes. I will set it to the base version of 1.26.0 so that I can practice upgrading it on a later date.
 * **--pod-network-cidr** - the range of IP addresses for the pod network. Take note of this value as we may need later when we install our CNI plugin.
```
# Create the cluster
$ sudo kubeadm init --apiserver-advertise-address 192.168.56.5 --kubernetes-version 1.26.0 --pod-network-cidr 192.168.0.0/24 -v 5
```  
The command above needs to be run on the Master VM.  
I am setting the verbosity of the output to 5 so that we can track what kubeadm will be doing.
## Using a Configuration File
Alternatively you can create a kubeadm init configuration file and pass it to kubeadm init using the '--config' parameter. This feature, as of 4/15/2023, is marked as beta, so it may change on a later date. You can get a template and the various options you can set on this [page](https://kubernetes.io/docs/reference/config-api/kubeadm-config.v1beta3/). You can also run 'kubeadm config print init-defaults' to quickly create a config file template to edit. You will only need the 'ClusterConfiguration' section to setup a cluster. Converting our parameters above my config file would look like this:
```
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: "192.168.56.5"
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
networking:
  podSubnet: "10.244.0.0/24"
kubernetesVersion: "v1.26.0"
clusterName: "my-k8s-cluster"
```
I have saved this [my-k8s-cluster.yaml](../vagrant/virtualbox_setup/my-k8s-cluster.yaml).  To run this I will use:  
```
# Create my cluster using a kubeadm config file
$ sudo kubeadm init --config ./my-k8s-cluster.yaml -v 5
```  
